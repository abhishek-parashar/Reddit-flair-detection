{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model",
      "provenance": [],
      "authorship_tag": "ABX9TyOT1cT2tZTQB9Pyi8SU950N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishek-parashar/Reddit-flair-detection/blob/master/scripts/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exhielZubZ9v",
        "colab_type": "text"
      },
      "source": [
        "## Importing the Required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXBPJXyVPTSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "edd60ba2-41d3-4648-a418-af522928c77c"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.externals import joblib\n",
        "from xgboost import XGBClassifier\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40GM5UYLcZ3B",
        "colab_type": "text"
      },
      "source": [
        "##loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efumd_cycPBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv('datafinal.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4zaAejIkttw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "ffcabbe5-3e47-4ac0-cb78-e875e660614b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>flair</th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>comms_num</th>\n",
              "      <th>body</th>\n",
              "      <th>author</th>\n",
              "      <th>comments</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>combined_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>4 days ago pending orders 100 million hydroxyc...</td>\n",
              "      <td>93</td>\n",
              "      <td>fwjdqr</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/fwjdqr...</td>\n",
              "      <td>6</td>\n",
              "      <td>getting frantic calls pharma customers delayed...</td>\n",
              "      <td>india_ko_vanakkam</td>\n",
              "      <td>modi stockholm syndrome fair evidence chloroqu...</td>\n",
              "      <td>2020-04-07 20:07:04</td>\n",
              "      <td>4 days ago pending orders 100 million hydroxyc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>randians big time users dating apps like tinde...</td>\n",
              "      <td>18</td>\n",
              "      <td>fizkkk</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/fizkkk...</td>\n",
              "      <td>19</td>\n",
              "      <td>id stint apps couple months one point didnt fe...</td>\n",
              "      <td>__knockknockturnal__</td>\n",
              "      <td>someone matched tell im fat cat 1 general foll...</td>\n",
              "      <td>2020-03-15 18:48:06</td>\n",
              "      <td>randians big time users dating apps like tinde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>r india thinks flat earthers</td>\n",
              "      <td>7</td>\n",
              "      <td>f25vx0</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/f25vx0...</td>\n",
              "      <td>31</td>\n",
              "      <td>encountered foreigner ig says round earth hoax...</td>\n",
              "      <td>Dev1003</td>\n",
              "      <td>havent found indian yet believes earth flat de...</td>\n",
              "      <td>2020-02-11 17:10:55</td>\n",
              "      <td>r india thinks flat earthershavent found india...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>people left 9 5 jobs pursue career music art f...</td>\n",
              "      <td>44</td>\n",
              "      <td>dtvliq</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/dtvliq...</td>\n",
              "      <td>34</td>\n",
              "      <td>couldnt add askindia flair mobile browser</td>\n",
              "      <td>c0mrade34</td>\n",
              "      <td>engineer advertisement shoots since last 1year...</td>\n",
              "      <td>2019-11-09 20:57:35</td>\n",
              "      <td>people left 9 5 jobs pursue career music art f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AskIndia</td>\n",
              "      <td>somebody want kill full family</td>\n",
              "      <td>97</td>\n",
              "      <td>b7pvwt</td>\n",
              "      <td>https://www.reddit.com/r/india/comments/b7pvwt...</td>\n",
              "      <td>24</td>\n",
              "      <td>24hrs local police station register case dont ...</td>\n",
              "      <td>amitkumarthakur</td>\n",
              "      <td>calm downgo sp office town file grievance imme...</td>\n",
              "      <td>2019-04-01 01:00:35</td>\n",
              "      <td>somebody want kill full familycalm downgo sp o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                  combined_features\n",
              "0           0  ...  4 days ago pending orders 100 million hydroxyc...\n",
              "1           1  ...  randians big time users dating apps like tinde...\n",
              "2           2  ...  r india thinks flat earthershavent found india...\n",
              "3           3  ...  people left 9 5 jobs pursue career music art f...\n",
              "4           4  ...  somebody want kill full familycalm downgo sp o...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz1F_coOcV0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.fillna(\"\",inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpEaY8P6xCjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87239db9-38a9-40b2-cb2d-f8243519725f"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1218, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kHtrl0-lHaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "09fccfcc-95fa-47d8-afff-9af65fb8cbce"
      },
      "source": [
        "data['flair'].unique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AskIndia', 'Non-Political', '[R]eddiquette', 'Scheduled',\n",
              "       'Photography', 'Science/Technology', 'Politics',\n",
              "       'Business/Finance', 'Policy/Economy', 'Sports', 'Food', 'AMA',\n",
              "       'Coronavirus'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gub4fbYHk_ME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flair = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \n",
        "          \"Scheduled\", \"Photography\", \"Science/Technology\",\n",
        "          \"Politics\", \"Business/Finance\", \"Policy/Economy\",\n",
        "          \"Sports\", \"Food\", \"AMA\",\"Coronavirus\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhlqsfLHd3cJ",
        "colab_type": "text"
      },
      "source": [
        "## Trying different models \n",
        "## though there are different models but cince this is a cassification task so I am using some of the models which work with classification and thn comparing their results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHMJkbNeedSw",
        "colab_type": "text"
      },
      "source": [
        "svm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_NTnvMEcjZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_svm(X_train, X_test, y_train, y_test):\n",
        "  sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', SGDClassifier(loss='hinge',alpha=1e-4, random_state=16, max_iter=5, tol=None)),\n",
        "                 ])\n",
        "  sgd.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = sgd.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flair))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a996ktiree0f",
        "colab_type": "text"
      },
      "source": [
        "random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b_L6wrJeYrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def randomforest(X_train, X_test, y_train, y_test):\n",
        "  ranfor = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
        "                 ])\n",
        "  ranfor.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = ranfor.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flair))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AguxwAACetky",
        "colab_type": "text"
      },
      "source": [
        "mlp classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkKkxbTWelo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mlpclassifier(X_train, X_test, y_train, y_test):  \n",
        "  mlp = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,30,30))),\n",
        "                 ])\n",
        "  mlp.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = mlp.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flair))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aij7yIkCexgg",
        "colab_type": "text"
      },
      "source": [
        "xgboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI_lTZhvewue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xgbclassifier(X_train, X_test, y_train, y_test):  \n",
        "    xgb_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', XGBClassifier(random_state=42, seed=2,n_estimators=1000,verbosity=1,objective='multi:softmax')),\n",
        "                 ])\n",
        "    xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "    print(classification_report(y_test, y_pred,target_names=flair))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6muBjUqskyuK",
        "colab_type": "text"
      },
      "source": [
        "logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKnFdvSGtas2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logisticreg(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "  logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                  ('tfidf', TfidfTransformer()),\n",
        "                  ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "                 ])\n",
        "  logreg.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = logreg.predict(X_test)\n",
        "\n",
        "  print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "  print(classification_report(y_test, y_pred,target_names=flair))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2lPaWWOjue1",
        "colab_type": "text"
      },
      "source": [
        "## Let's Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AQjx5Bxi53r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test(X,y):\n",
        " \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
        "    print(\"Results of Linear Support Vector Machine\")\n",
        "    linear_svm(X_train, X_test, y_train, y_test)\n",
        "    print(\"Results of Logistic Regression\")\n",
        "    logisticreg(X_train, X_test, y_train, y_test)\n",
        "    print(\"Results of Random Forest\")\n",
        "    randomforest(X_train, X_test, y_train, y_test)\n",
        "    print(\"Results of MLP Classifier\")\n",
        "    mlpclassifier(X_train, X_test, y_train, y_test)\n",
        "    print(\"Results of XGB Classifier\")\n",
        "    xgbclassifier(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JXGVd7cj7ez",
        "colab_type": "text"
      },
      "source": [
        "for evaluation comments, title, url, body and combined features are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbsHzK0gjp1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9725bbc0-4203-4da0-db5c-fd9f19f075a5"
      },
      "source": [
        "\n",
        "cat = data['flair']\n",
        "\n",
        "V = data['combined_features']\n",
        "W = data['comments']\n",
        "X = data['title']\n",
        "Y = data['body']\n",
        "Z = data['url']\n",
        "\n",
        "print(\"Flair Detection using Title as Feature\")\n",
        "train_test(X,cat)\n",
        "print(\"Flair Detection using Body as Feature\")\n",
        "train_test(Y,cat)\n",
        "print(\"Flair Detection using URL as Feature\")\n",
        "train_test(Z,cat)\n",
        "print(\"Flair Detection using Comments as Feature\")\n",
        "train_test(W,cat)\n",
        "print(\"Flair Detection using Combined Features\")\n",
        "train_test(V,cat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flair Detection using Title as Feature\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.7418032786885246\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.60      0.75      0.67        16\n",
            "     Non-Political       0.60      0.79      0.68        19\n",
            "     [R]eddiquette       0.45      0.29      0.36        17\n",
            "         Scheduled       0.75      0.88      0.81        17\n",
            "       Photography       0.81      0.91      0.86        23\n",
            "Science/Technology       0.88      0.95      0.91        22\n",
            "          Politics       0.96      0.96      0.96        25\n",
            "  Business/Finance       0.50      0.50      0.50        18\n",
            "    Policy/Economy       0.83      0.76      0.79        25\n",
            "            Sports       0.67      0.63      0.65        19\n",
            "              Food       0.78      0.67      0.72        21\n",
            "               AMA       0.88      0.74      0.80        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.74       244\n",
            "         macro avg       0.67      0.68      0.67       244\n",
            "      weighted avg       0.73      0.74      0.73       244\n",
            "\n",
            "Results of Logistic Regression\n",
            "accuracy 0.7540983606557377\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.75      0.75      0.75        16\n",
            "     Non-Political       0.64      0.84      0.73        19\n",
            "     [R]eddiquette       0.38      0.35      0.36        17\n",
            "         Scheduled       0.94      0.88      0.91        17\n",
            "       Photography       0.84      0.91      0.87        23\n",
            "Science/Technology       0.91      0.95      0.93        22\n",
            "          Politics       1.00      0.96      0.98        25\n",
            "  Business/Finance       0.55      0.67      0.60        18\n",
            "    Policy/Economy       0.75      0.72      0.73        25\n",
            "            Sports       0.67      0.63      0.65        19\n",
            "              Food       0.72      0.62      0.67        21\n",
            "               AMA       0.82      0.74      0.78        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.75       244\n",
            "         macro avg       0.69      0.69      0.69       244\n",
            "      weighted avg       0.75      0.75      0.75       244\n",
            "\n",
            "Results of Random Forest\n",
            "accuracy 0.7336065573770492\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.71      0.75      0.73        16\n",
            "     Non-Political       0.87      0.68      0.76        19\n",
            "     [R]eddiquette       0.44      0.24      0.31        17\n",
            "         Scheduled       0.88      0.88      0.88        17\n",
            "       Photography       0.91      0.87      0.89        23\n",
            "Science/Technology       0.92      1.00      0.96        22\n",
            "          Politics       0.83      0.96      0.89        25\n",
            "  Business/Finance       0.43      0.56      0.49        18\n",
            "    Policy/Economy       0.75      0.72      0.73        25\n",
            "            Sports       0.76      0.68      0.72        19\n",
            "              Food       0.93      0.67      0.78        21\n",
            "               AMA       0.44      0.74      0.55        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.73       244\n",
            "         macro avg       0.68      0.67      0.67       244\n",
            "      weighted avg       0.74      0.73      0.73       244\n",
            "\n",
            "Results of MLP Classifier\n",
            "accuracy 0.5327868852459017\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.38      0.62      0.48        16\n",
            "     Non-Political       0.47      0.47      0.47        19\n",
            "     [R]eddiquette       0.25      0.24      0.24        17\n",
            "         Scheduled       0.57      0.47      0.52        17\n",
            "       Photography       0.68      0.65      0.67        23\n",
            "Science/Technology       0.68      0.59      0.63        22\n",
            "          Politics       1.00      0.60      0.75        25\n",
            "  Business/Finance       0.50      0.44      0.47        18\n",
            "    Policy/Economy       0.71      0.48      0.57        25\n",
            "            Sports       0.58      0.58      0.58        19\n",
            "              Food       0.63      0.57      0.60        21\n",
            "               AMA       0.31      0.68      0.43        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.53       244\n",
            "         macro avg       0.52      0.49      0.49       244\n",
            "      weighted avg       0.58      0.53      0.54       244\n",
            "\n",
            "Results of XGB Classifier\n",
            "accuracy 0.7008196721311475\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.87      0.81      0.84        16\n",
            "     Non-Political       0.78      0.74      0.76        19\n",
            "     [R]eddiquette       0.38      0.29      0.33        17\n",
            "         Scheduled       0.94      0.88      0.91        17\n",
            "       Photography       0.88      0.91      0.89        23\n",
            "Science/Technology       0.91      0.95      0.93        22\n",
            "          Politics       0.95      0.84      0.89        25\n",
            "  Business/Finance       0.35      0.44      0.39        18\n",
            "    Policy/Economy       0.78      0.56      0.65        25\n",
            "            Sports       0.86      0.63      0.73        19\n",
            "              Food       0.94      0.71      0.81        21\n",
            "               AMA       0.30      0.63      0.41        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.70       244\n",
            "         macro avg       0.69      0.65      0.66       244\n",
            "      weighted avg       0.75      0.70      0.71       244\n",
            "\n",
            "Flair Detection using Body as Feature\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.3442622950819672\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.53      0.62      0.57        16\n",
            "     Non-Political       0.47      0.37      0.41        19\n",
            "     [R]eddiquette       0.60      0.53      0.56        17\n",
            "         Scheduled       0.14      0.88      0.24        17\n",
            "       Photography       0.67      0.17      0.28        23\n",
            "Science/Technology       0.22      0.09      0.13        22\n",
            "          Politics       0.83      0.40      0.54        25\n",
            "  Business/Finance       0.40      0.44      0.42        18\n",
            "    Policy/Economy       0.50      0.08      0.14        25\n",
            "            Sports       0.58      0.37      0.45        19\n",
            "              Food       0.40      0.19      0.26        21\n",
            "               AMA       0.38      0.26      0.31        19\n",
            "       Coronavirus       1.00      0.33      0.50         3\n",
            "\n",
            "          accuracy                           0.34       244\n",
            "         macro avg       0.52      0.37      0.37       244\n",
            "      weighted avg       0.49      0.34      0.35       244\n",
            "\n",
            "Results of Logistic Regression\n",
            "accuracy 0.3237704918032787\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.43      0.62      0.51        16\n",
            "     Non-Political       0.20      0.05      0.08        19\n",
            "     [R]eddiquette       0.41      0.65      0.50        17\n",
            "         Scheduled       0.14      0.88      0.24        17\n",
            "       Photography       0.67      0.17      0.28        23\n",
            "Science/Technology       0.33      0.05      0.08        22\n",
            "          Politics       0.92      0.44      0.59        25\n",
            "  Business/Finance       0.32      0.33      0.32        18\n",
            "    Policy/Economy       0.50      0.08      0.14        25\n",
            "            Sports       0.38      0.32      0.34        19\n",
            "              Food       0.56      0.24      0.33        21\n",
            "               AMA       0.46      0.32      0.37        19\n",
            "       Coronavirus       1.00      0.33      0.50         3\n",
            "\n",
            "          accuracy                           0.32       244\n",
            "         macro avg       0.49      0.34      0.33       244\n",
            "      weighted avg       0.47      0.32      0.31       244\n",
            "\n",
            "Results of Random Forest\n",
            "accuracy 0.3770491803278688\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.59      0.62      0.61        16\n",
            "     Non-Political       0.32      0.63      0.43        19\n",
            "     [R]eddiquette       0.91      0.59      0.71        17\n",
            "         Scheduled       0.14      0.88      0.24        17\n",
            "       Photography       0.62      0.22      0.32        23\n",
            "Science/Technology       0.00      0.00      0.00        22\n",
            "          Politics       1.00      0.44      0.61        25\n",
            "  Business/Finance       0.45      0.50      0.47        18\n",
            "    Policy/Economy       0.40      0.08      0.13        25\n",
            "            Sports       0.86      0.32      0.46        19\n",
            "              Food       0.88      0.33      0.48        21\n",
            "               AMA       0.62      0.26      0.37        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.38       244\n",
            "         macro avg       0.52      0.38      0.37       244\n",
            "      weighted avg       0.56      0.38      0.39       244\n",
            "\n",
            "Results of MLP Classifier\n",
            "accuracy 0.26639344262295084\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.73      0.50      0.59        16\n",
            "     Non-Political       0.00      0.00      0.00        19\n",
            "     [R]eddiquette       0.26      0.59      0.36        17\n",
            "         Scheduled       0.14      0.88      0.24        17\n",
            "       Photography       0.50      0.04      0.08        23\n",
            "Science/Technology       0.29      0.09      0.14        22\n",
            "          Politics       0.67      0.40      0.50        25\n",
            "  Business/Finance       0.21      0.17      0.19        18\n",
            "    Policy/Economy       0.43      0.12      0.19        25\n",
            "            Sports       0.27      0.32      0.29        19\n",
            "              Food       0.23      0.14      0.18        21\n",
            "               AMA       0.80      0.21      0.33        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.27       244\n",
            "         macro avg       0.35      0.27      0.24       244\n",
            "      weighted avg       0.38      0.27      0.25       244\n",
            "\n",
            "Results of XGB Classifier\n",
            "accuracy 0.36885245901639346\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.62      0.50      0.55        16\n",
            "     Non-Political       0.38      0.42      0.40        19\n",
            "     [R]eddiquette       0.83      0.59      0.69        17\n",
            "         Scheduled       0.14      0.88      0.23        17\n",
            "       Photography       0.71      0.22      0.33        23\n",
            "Science/Technology       0.14      0.05      0.07        22\n",
            "          Politics       0.85      0.44      0.58        25\n",
            "  Business/Finance       0.54      0.39      0.45        18\n",
            "    Policy/Economy       0.44      0.16      0.24        25\n",
            "            Sports       0.27      0.21      0.24        19\n",
            "              Food       0.89      0.38      0.53        21\n",
            "               AMA       0.73      0.42      0.53        19\n",
            "       Coronavirus       0.33      0.33      0.33         3\n",
            "\n",
            "          accuracy                           0.37       244\n",
            "         macro avg       0.53      0.38      0.40       244\n",
            "      weighted avg       0.55      0.37      0.40       244\n",
            "\n",
            "Flair Detection using URL as Feature\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.27459016393442626\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        16\n",
            "     Non-Political       0.00      0.00      0.00        19\n",
            "     [R]eddiquette       0.20      0.06      0.09        17\n",
            "         Scheduled       0.82      0.82      0.82        17\n",
            "       Photography       0.67      0.35      0.46        23\n",
            "Science/Technology       0.10      0.64      0.17        22\n",
            "          Politics       0.37      0.28      0.32        25\n",
            "  Business/Finance       0.44      0.22      0.30        18\n",
            "    Policy/Economy       0.56      0.36      0.44        25\n",
            "            Sports       0.25      0.05      0.09        19\n",
            "              Food       0.50      0.24      0.32        21\n",
            "               AMA       1.00      0.21      0.35        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.27       244\n",
            "         macro avg       0.38      0.25      0.26       244\n",
            "      weighted avg       0.41      0.27      0.28       244\n",
            "\n",
            "Results of Logistic Regression\n",
            "accuracy 0.3073770491803279\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        16\n",
            "     Non-Political       0.14      1.00      0.25        19\n",
            "     [R]eddiquette       0.22      0.12      0.15        17\n",
            "         Scheduled       0.78      0.82      0.80        17\n",
            "       Photography       0.67      0.35      0.46        23\n",
            "Science/Technology       0.67      0.18      0.29        22\n",
            "          Politics       0.40      0.16      0.23        25\n",
            "  Business/Finance       0.62      0.28      0.38        18\n",
            "    Policy/Economy       0.60      0.36      0.45        25\n",
            "            Sports       0.33      0.05      0.09        19\n",
            "              Food       0.50      0.24      0.32        21\n",
            "               AMA       1.00      0.21      0.35        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.31       244\n",
            "         macro avg       0.46      0.29      0.29       244\n",
            "      weighted avg       0.50      0.31      0.31       244\n",
            "\n",
            "Results of Random Forest\n",
            "accuracy 0.26229508196721313\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        16\n",
            "     Non-Political       0.00      0.00      0.00        19\n",
            "     [R]eddiquette       0.09      0.76      0.17        17\n",
            "         Scheduled       0.67      0.82      0.74        17\n",
            "       Photography       0.36      0.39      0.37        23\n",
            "Science/Technology       0.29      0.18      0.22        22\n",
            "          Politics       0.25      0.04      0.07        25\n",
            "  Business/Finance       0.67      0.22      0.33        18\n",
            "    Policy/Economy       0.75      0.36      0.49        25\n",
            "            Sports       0.43      0.16      0.23        19\n",
            "              Food       0.33      0.19      0.24        21\n",
            "               AMA       1.00      0.16      0.27        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.26       244\n",
            "         macro avg       0.37      0.25      0.24       244\n",
            "      weighted avg       0.40      0.26      0.26       244\n",
            "\n",
            "Results of MLP Classifier\n",
            "accuracy 0.22540983606557377\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.10      0.88      0.18        16\n",
            "     Non-Political       0.00      0.00      0.00        19\n",
            "     [R]eddiquette       0.00      0.00      0.00        17\n",
            "         Scheduled       0.89      0.47      0.62        17\n",
            "       Photography       0.60      0.26      0.36        23\n",
            "Science/Technology       0.27      0.14      0.18        22\n",
            "          Politics       0.29      0.08      0.12        25\n",
            "  Business/Finance       0.43      0.17      0.24        18\n",
            "    Policy/Economy       0.60      0.36      0.45        25\n",
            "            Sports       0.12      0.11      0.11        19\n",
            "              Food       0.80      0.19      0.31        21\n",
            "               AMA       0.19      0.21      0.20        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.23       244\n",
            "         macro avg       0.33      0.22      0.21       244\n",
            "      weighted avg       0.37      0.23      0.23       244\n",
            "\n",
            "Results of XGB Classifier\n",
            "accuracy 0.21721311475409835\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.00      0.00      0.00        16\n",
            "     Non-Political       0.00      0.00      0.00        19\n",
            "     [R]eddiquette       0.00      0.00      0.00        17\n",
            "         Scheduled       0.50      0.47      0.48        17\n",
            "       Photography       0.28      0.30      0.29        23\n",
            "Science/Technology       0.23      0.14      0.17        22\n",
            "          Politics       0.40      0.16      0.23        25\n",
            "  Business/Finance       0.50      0.17      0.25        18\n",
            "    Policy/Economy       0.73      0.32      0.44        25\n",
            "            Sports       0.00      0.00      0.00        19\n",
            "              Food       0.12      0.86      0.21        21\n",
            "               AMA       0.40      0.11      0.17        19\n",
            "       Coronavirus       0.00      0.00      0.00         3\n",
            "\n",
            "          accuracy                           0.22       244\n",
            "         macro avg       0.24      0.19      0.17       244\n",
            "      weighted avg       0.28      0.22      0.20       244\n",
            "\n",
            "Flair Detection using Comments as Feature\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.430327868852459\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.40      0.50      0.44        16\n",
            "     Non-Political       0.08      0.05      0.06        19\n",
            "     [R]eddiquette       0.45      0.29      0.36        17\n",
            "         Scheduled       0.29      0.12      0.17        17\n",
            "       Photography       0.45      0.65      0.54        23\n",
            "Science/Technology       0.22      0.09      0.13        22\n",
            "          Politics       0.46      0.76      0.58        25\n",
            "  Business/Finance       0.28      0.39      0.33        18\n",
            "    Policy/Economy       0.52      0.52      0.52        25\n",
            "            Sports       0.62      0.42      0.50        19\n",
            "              Food       0.50      0.52      0.51        21\n",
            "               AMA       0.50      0.63      0.56        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.43       244\n",
            "         macro avg       0.44      0.43      0.42       244\n",
            "      weighted avg       0.41      0.43      0.41       244\n",
            "\n",
            "Results of Logistic Regression\n",
            "accuracy 0.4344262295081967\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.29      0.69      0.41        16\n",
            "     Non-Political       0.21      0.16      0.18        19\n",
            "     [R]eddiquette       0.64      0.41      0.50        17\n",
            "         Scheduled       0.24      0.35      0.29        17\n",
            "       Photography       0.62      0.70      0.65        23\n",
            "Science/Technology       0.14      0.05      0.07        22\n",
            "          Politics       0.79      0.60      0.68        25\n",
            "  Business/Finance       0.25      0.39      0.30        18\n",
            "    Policy/Economy       0.44      0.48      0.46        25\n",
            "            Sports       0.58      0.37      0.45        19\n",
            "              Food       0.43      0.43      0.43        21\n",
            "               AMA       0.71      0.53      0.61        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.43       244\n",
            "         macro avg       0.49      0.45      0.45       244\n",
            "      weighted avg       0.46      0.43      0.43       244\n",
            "\n",
            "Results of Random Forest\n",
            "accuracy 0.4385245901639344\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.43      0.75      0.55        16\n",
            "     Non-Political       0.31      0.26      0.29        19\n",
            "     [R]eddiquette       0.50      0.41      0.45        17\n",
            "         Scheduled       0.21      0.53      0.30        17\n",
            "       Photography       0.54      0.61      0.57        23\n",
            "Science/Technology       0.17      0.09      0.12        22\n",
            "          Politics       0.60      0.60      0.60        25\n",
            "  Business/Finance       0.33      0.28      0.30        18\n",
            "    Policy/Economy       0.52      0.48      0.50        25\n",
            "            Sports       0.45      0.26      0.33        19\n",
            "              Food       0.54      0.33      0.41        21\n",
            "               AMA       0.75      0.63      0.69        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.44       244\n",
            "         macro avg       0.49      0.45      0.45       244\n",
            "      weighted avg       0.46      0.44      0.43       244\n",
            "\n",
            "Results of MLP Classifier\n",
            "accuracy 0.3073770491803279\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.41      0.44      0.42        16\n",
            "     Non-Political       0.00      0.00      0.00        19\n",
            "     [R]eddiquette       0.33      0.12      0.17        17\n",
            "         Scheduled       0.18      0.29      0.22        17\n",
            "       Photography       0.56      0.43      0.49        23\n",
            "Science/Technology       0.33      0.05      0.08        22\n",
            "          Politics       0.77      0.68      0.72        25\n",
            "  Business/Finance       0.27      0.33      0.30        18\n",
            "    Policy/Economy       0.60      0.12      0.20        25\n",
            "            Sports       0.25      0.05      0.09        19\n",
            "              Food       0.16      0.62      0.26        21\n",
            "               AMA       0.36      0.42      0.39        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.31       244\n",
            "         macro avg       0.40      0.32      0.32       244\n",
            "      weighted avg       0.38      0.31      0.29       244\n",
            "\n",
            "Results of XGB Classifier\n",
            "accuracy 0.4180327868852459\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.56      0.62      0.59        16\n",
            "     Non-Political       0.20      0.21      0.21        19\n",
            "     [R]eddiquette       0.43      0.35      0.39        17\n",
            "         Scheduled       0.19      0.47      0.27        17\n",
            "       Photography       0.60      0.52      0.56        23\n",
            "Science/Technology       0.18      0.14      0.15        22\n",
            "          Politics       0.68      0.52      0.59        25\n",
            "  Business/Finance       0.50      0.44      0.47        18\n",
            "    Policy/Economy       0.55      0.44      0.49        25\n",
            "            Sports       0.41      0.37      0.39        19\n",
            "              Food       0.39      0.33      0.36        21\n",
            "               AMA       0.52      0.58      0.55        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.42       244\n",
            "         macro avg       0.48      0.44      0.45       244\n",
            "      weighted avg       0.45      0.42      0.43       244\n",
            "\n",
            "Flair Detection using Combined Features\n",
            "Results of Linear Support Vector Machine\n",
            "accuracy 0.7090163934426229\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.64      0.56      0.60        16\n",
            "     Non-Political       0.73      0.42      0.53        19\n",
            "     [R]eddiquette       0.69      0.53      0.60        17\n",
            "         Scheduled       1.00      0.82      0.90        17\n",
            "       Photography       0.71      0.87      0.78        23\n",
            "Science/Technology       0.61      0.50      0.55        22\n",
            "          Politics       1.00      0.92      0.96        25\n",
            "  Business/Finance       0.38      0.61      0.47        18\n",
            "    Policy/Economy       0.65      0.68      0.67        25\n",
            "            Sports       0.70      0.84      0.76        19\n",
            "              Food       0.67      0.76      0.71        21\n",
            "               AMA       0.89      0.89      0.89        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.71       244\n",
            "         macro avg       0.74      0.70      0.71       244\n",
            "      weighted avg       0.73      0.71      0.71       244\n",
            "\n",
            "Results of Logistic Regression\n",
            "accuracy 0.7131147540983607\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.52      0.69      0.59        16\n",
            "     Non-Political       0.53      0.42      0.47        19\n",
            "     [R]eddiquette       0.77      0.59      0.67        17\n",
            "         Scheduled       1.00      0.76      0.87        17\n",
            "       Photography       0.74      0.87      0.80        23\n",
            "Science/Technology       0.55      0.50      0.52        22\n",
            "          Politics       1.00      0.84      0.91        25\n",
            "  Business/Finance       0.55      0.67      0.60        18\n",
            "    Policy/Economy       0.67      0.72      0.69        25\n",
            "            Sports       0.68      0.79      0.73        19\n",
            "              Food       0.76      0.76      0.76        21\n",
            "               AMA       0.85      0.89      0.87        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.71       244\n",
            "         macro avg       0.74      0.71      0.71       244\n",
            "      weighted avg       0.73      0.71      0.71       244\n",
            "\n",
            "Results of Random Forest\n",
            "accuracy 0.7745901639344263\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.55      0.75      0.63        16\n",
            "     Non-Political       0.68      0.68      0.68        19\n",
            "     [R]eddiquette       0.92      0.71      0.80        17\n",
            "         Scheduled       0.58      0.88      0.70        17\n",
            "       Photography       0.81      0.74      0.77        23\n",
            "Science/Technology       0.67      0.55      0.60        22\n",
            "          Politics       0.92      0.96      0.94        25\n",
            "  Business/Finance       0.62      0.83      0.71        18\n",
            "    Policy/Economy       0.89      0.68      0.77        25\n",
            "            Sports       0.94      0.79      0.86        19\n",
            "              Food       0.86      0.86      0.86        21\n",
            "               AMA       1.00      0.89      0.94        19\n",
            "       Coronavirus       1.00      0.67      0.80         3\n",
            "\n",
            "          accuracy                           0.77       244\n",
            "         macro avg       0.80      0.77      0.77       244\n",
            "      weighted avg       0.80      0.77      0.78       244\n",
            "\n",
            "Results of MLP Classifier\n",
            "accuracy 0.5532786885245902\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.54      0.44      0.48        16\n",
            "     Non-Political       0.19      0.47      0.27        19\n",
            "     [R]eddiquette       0.39      0.65      0.49        17\n",
            "         Scheduled       0.85      0.65      0.73        17\n",
            "       Photography       0.66      0.83      0.73        23\n",
            "Science/Technology       0.38      0.36      0.37        22\n",
            "          Politics       0.81      0.84      0.82        25\n",
            "  Business/Finance       0.67      0.44      0.53        18\n",
            "    Policy/Economy       0.80      0.32      0.46        25\n",
            "            Sports       0.60      0.47      0.53        19\n",
            "              Food       0.71      0.57      0.63        21\n",
            "               AMA       0.92      0.58      0.71        19\n",
            "       Coronavirus       1.00      0.33      0.50         3\n",
            "\n",
            "          accuracy                           0.55       244\n",
            "         macro avg       0.65      0.54      0.56       244\n",
            "      weighted avg       0.64      0.55      0.57       244\n",
            "\n",
            "Results of XGB Classifier\n",
            "accuracy 0.8278688524590164\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "          AskIndia       0.81      0.81      0.81        16\n",
            "     Non-Political       0.78      0.74      0.76        19\n",
            "     [R]eddiquette       0.83      0.88      0.86        17\n",
            "         Scheduled       0.81      0.76      0.79        17\n",
            "       Photography       0.78      0.91      0.84        23\n",
            "Science/Technology       0.73      0.73      0.73        22\n",
            "          Politics       0.96      0.92      0.94        25\n",
            "  Business/Finance       0.78      0.78      0.78        18\n",
            "    Policy/Economy       0.80      0.64      0.71        25\n",
            "            Sports       0.85      0.89      0.87        19\n",
            "              Food       0.86      0.90      0.88        21\n",
            "               AMA       0.90      0.95      0.92        19\n",
            "       Coronavirus       1.00      1.00      1.00         3\n",
            "\n",
            "          accuracy                           0.83       244\n",
            "         macro avg       0.84      0.84      0.84       244\n",
            "      weighted avg       0.83      0.83      0.83       244\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNSHWwap33J6",
        "colab_type": "text"
      },
      "source": [
        "## saving the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrPxeYx636dH",
        "colab_type": "text"
      },
      "source": [
        "I have used job lib to save the model earlier I used pickle but it gave errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzyhwbgbkg_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "X_train, X_test, y_train, y_test = train_test_split(V, cat, test_size=0.2, random_state = 42)\n",
        "model = Pipeline([('vect', CountVectorizer()),\n",
        "                   ('tfidf', TfidfTransformer()),\n",
        "                   ('clf', xgb.sklearn.XGBClassifier(random_state=42,n_estimators=1000,verbosity=1, seed=2, colsample_bytree=0.6, subsample=0.7,objective='multi:softmax')),\n",
        "                  ])\n",
        "XGB = model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-JNmzR24dss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joblib.dump(XGB, open('xgb.bin', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrDLeKvG6jcd",
        "colab_type": "text"
      },
      "source": [
        "## Before deploying the model to webiste first let's check the prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvq9b-LZ6v8z",
        "colab_type": "text"
      },
      "source": [
        "loading the model and all the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3JmVLjA44Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_final=joblib.load(open('xgb.bin', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLEdnRnj7OmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "54228b84-36d5-4834-97f2-d46d1d03b59e"
      },
      "source": [
        "\n",
        "!pip install praw"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting praw\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/39/17251486951815d4514e4a3f179d4f3e7af5f7b1ce8eaba5a3ea61bc91f2/praw-7.0.0-py3-none-any.whl (143kB)\n",
            "\u001b[K     || 153kB 4.7MB/s \n",
            "\u001b[?25hCollecting update-checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
            "Collecting websocket-client>=0.54.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     || 204kB 15.5MB/s \n",
            "\u001b[?25hCollecting prawcore<2.0,>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/8e/d076cb8f26523f91eef3e75d6cf9143b2f16d67ce7d681a61d0bbc783f49/prawcore-1.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->praw) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client>=0.54.0->praw) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->praw) (3.0.4)\n",
            "Installing collected packages: update-checker, websocket-client, prawcore, praw\n",
            "Successfully installed praw-7.0.0 prawcore-1.3.0 update-checker-0.16 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5blW3C7V0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c50a435-1bc4-4101-9bff-76b3cc700225"
      },
      "source": [
        "import praw\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import datetime as dt\n",
        "nltk.download('all')\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FXrSqqaQkME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = model_final\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26BlzPmd7aRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reddit = praw.Reddit(client_id='QPdCUgBcp4WinA', client_secret='HF-sKHVC5Os3gufVxWvzIKijNb4', user_agent='reddit-flair', username='reddit-flair', password='flair123')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OWVGnBO7l0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def text_cleaning(text):\n",
        "   \n",
        "    text = BeautifulSoup(text, \"lxml\").text\n",
        "    text = text.lower()\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "    return text\n",
        "\n",
        "def string(value):\n",
        "    return str(value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bbmZdDrHrRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def prediction(url):\n",
        "\tsubmission = reddit.submission(url = url)\n",
        "\tdata = {}\n",
        "\tdata[\"title\"] =str(submission.title)\n",
        "\tdata[\"url\"] = str(submission.url)\n",
        "\tdata[\"body\"] = str(submission.selftext)\n",
        "\n",
        "\tsubmission.comments.replace_more(limit=None)\n",
        "\tcomment = ''\n",
        "\tcount = 0\n",
        "\tfor top_level_comment in submission.comments:\n",
        "\t\tcomment = comment + ' ' + top_level_comment.body\n",
        "\t\tcount+=1\n",
        "\t\tif(count > 10):\n",
        "\t\t \tbreak\n",
        "\t\t\n",
        "\tdata[\"comment\"] = str(comment)\n",
        "\n",
        "\tdata['title'] = text_cleaning(str(data['title']))\n",
        "\tdata['body'] = text_cleaning(str(data['body']))\n",
        "\tdata['comment'] = text_cleaning(str(data['comment']))\n",
        "    \n",
        "\tcombined_features = data[\"title\"] + data[\"comment\"] + data[\"body\"] + data[\"url\"]\n",
        "\n",
        "\treturn str(model.predict([combined_features]))[2:-2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFUIwtCgOEKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc0ae2b2-49a2-4501-902a-8508d091d80e"
      },
      "source": [
        "prediction(\"https://www.reddit.com/r/india/comments/d1m9ld/iran_removes_antiindia_banners_from_pak_consulate/\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Politics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh5R5M6iQHsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}